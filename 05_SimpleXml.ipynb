{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleXml.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "VrIDlK2mvNsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"SimpleXml.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1ZLBNKY4Cile4EZslasgQ0z9hMf4rZJBv\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np # for multidimensional arrays\n",
        "\n",
        "# Word index\n",
        "word_index = {}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "# word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "# word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "word_index[\".\"] = 4\n",
        "word_index[\"validationxml\"] = 5\n",
        "word_index[\"document\"] = 6\n",
        "word_index[\"displayxml\"] = 7\n",
        "word_index[\"sheets\"] = 8\n",
        "word_index[\"sheet\"] = 9\n",
        "word_index[\"root\"] = 10\n",
        "word_index[\"node\"] = 11\n",
        "word_index[\"base\"] = 12\n",
        "word_index[\"dlitem\"] = 13\n",
        "word_index[\"member\"] = 14\n",
        "word_index[\"@X\"] = 15\n",
        "word_index[\"@Y\"] = 16\n",
        "word_index[\"@Z\"] = 17\n",
        "word_index\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "train_xml_0 = \"8.014999/8.014540/./validationxml/document/displayxml/sheets/sheet/document/root/node/base/base/node/base/base/dlitem/dlitem/dlitem/dlitem/dlitem/dlitem/member/@Z\"\n",
        "train_xml_1 = \"8.014999/8.014540/./validationxml/document/displayxml/sheets/sheet/document/root/node/base/base/node/base/base/dlitem/dlitem/dlitem/dlitem/dlitem/dlitem/member/@X\"\n",
        "train_xml_2 = \"8.014999/8.014540/./validationxml/document/displayxml/sheets/sheet/document/root/base/base/node/base/base/dlitem/dlitem/dlitem/dlitem/dlitem/dlitem/member/@Z\"\n",
        "train_xml_3 = \"8.014999/8.014540/./validationxml/document/displayxml/sheets/sheet/document/root/base/base/node/base/base/dlitem/dlitem/dlitem/dlitem/dlitem/dlitem/member/@X\"\n",
        "\n",
        "test_xml_0 = \"8.014999/8.014540/./validationxml/document/displayxml/sheets/sheet/document/root/node/base/base/base/node/base/base/dlitem/dlitem/dlitem/dlitem/dlitem/dlitem/member/@Z\"\n",
        "test_xml_1 = \"8.014999/8.014540/./validationxml/document/displayxml/sheets/sheet/document/root/node/base/base/base/node/base/base/dlitem/dlitem/dlitem/dlitem/dlitem/dlitem/member/@X\"\n",
        "\n",
        "# Convert each test xml array to values from 0.0-1.0\n",
        "def xml_to_input_arr(xml_str):\n",
        "  arr_xml = xml_str.split('/')\n",
        "  pads = [0] * (42 - len(arr_xml))\n",
        "  \n",
        "  word_values = []\n",
        "  for index, name in enumerate(arr_xml):\n",
        "    if index > 1: # skip baseline and compare values\n",
        "      word_values.append(word_index[name])\n",
        "      \n",
        "  word_values.extend(pads)\n",
        "  \n",
        "  np_word_values = np.array(word_values, dtype=np.uint8)\n",
        "  \n",
        "  np_word_bits = np.unpackbits(np_word_values)\n",
        "  \n",
        "  \n",
        "  np_word_bits = np_word_bits.astype(float) # convert values to float\n",
        "  np_word_bits = np.insert(np_word_bits, 0, float(arr_xml[1])/10.0) # hack for now\n",
        "  np_word_bits = np.insert(np_word_bits, 0, float(arr_xml[0])/10.0) # hack for now\n",
        "  \n",
        "  return np_word_bits\n",
        "\n",
        "# Initialize data\n",
        "train_data = np.ndarray(shape = (4,1,322))\n",
        "train_data[0] = [xml_to_input_arr(train_xml_0)]\n",
        "train_data[1] = [xml_to_input_arr(train_xml_1)]\n",
        "train_data[2] = [xml_to_input_arr(train_xml_2)]\n",
        "train_data[3] = [xml_to_input_arr(train_xml_3)]\n",
        "\n",
        "train_labels = np.ndarray(shape = (4,))\n",
        "train_labels[0] = 1\n",
        "train_labels[1] = 0\n",
        "train_labels[2] = 1\n",
        "train_labels[3] = 0\n",
        "\n",
        "test_data = np.ndarray(shape = (6,1,322))\n",
        "test_data[0] = [xml_to_input_arr(train_xml_0)]\n",
        "test_data[1] = [xml_to_input_arr(train_xml_1)]\n",
        "test_data[2] = [xml_to_input_arr(train_xml_2)]\n",
        "test_data[3] = [xml_to_input_arr(train_xml_3)]\n",
        "test_data[4] = [xml_to_input_arr(test_xml_0)]\n",
        "test_data[5] = [xml_to_input_arr(test_xml_1)]\n",
        "\n",
        "test_labels = np.ndarray(shape = (6,))\n",
        "test_labels[0] = 1\n",
        "test_labels[1] = 0\n",
        "test_labels[2] = 1\n",
        "test_labels[3] = 0\n",
        "test_labels[4] = 1\n",
        "test_labels[5] = 0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(1, 322)),\n",
        "  tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Our train_data is very short (just 4 items). We need lot of epochs to get somewhere\n",
        "model.fit(train_data, train_labels, epochs=100)\n",
        "\n",
        "# See final loss and accuracy\n",
        "model.evaluate(test_data, test_labels)\n",
        "\n",
        "# Review data\n",
        "predictions = model.predict(test_data)\n",
        "for index, test_data_item in enumerate(test_data):\n",
        "  print(\"Test_data index: \" + str(index) , \"Label: \" + str(test_labels[index]),  \"Prediction: \" + str(predictions[index]), \"Max Prediction: \" + str(np.argmax(predictions[index])))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}